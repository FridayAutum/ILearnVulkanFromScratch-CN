# 同步 synchronization



// 待完善

[TOC]



> Implementations have significant freedom to overlap execution of work submitted to a queue, and this is common due to deep pipelining and parallelism in Vulkan devices.

由于 Vulkan API 比起前辈 OpenGL 更加偏底层，写 Vulkan 代码的人就要担负起更多的责任，控制数据执行的同步就是其中一个。这可能是一件好事，因为人工打磨出来的同步模型可能更加能调度好 GPU 并使其饱和（saturated），从而获得性能上的提升，但如果没有搞清楚 Vulkan 中同步的概念，写出来的应用程序可就不仅仅是性能不好了，甚至有可能会出现错误。所以这章我就想仔细研究一下 Vulkan 中的同步机制。



## 指令类型

首先复习一下：Vulkan 中的指令包含三种（摘自 Vulkan doc 的 *2.2. Execution model*）：

* **action 类型**：draw, dispatch, clear, copy, query/timestamp operations, begin/end subpass operations

* **set state 类型**：bind pipelines, descriptor sets, and buffers, set dynamic state, push constants, set render pass/subpass state

  需要注意的是，state 类型指令并不会在 GPU 上“执行”，而是被 Host 用来标记每一个 action 类型指令的状态。

  > [State commands](https://www.khronos.org/registry/vulkan/specs/1.1/html/vkspec.html#fundamentals-queueoperation-command-types) do not execute any operations on the device, instead they set the state of the command buffer when they execute on the host, in the order that they are recorded. [Action commands](https://www.khronos.org/registry/vulkan/specs/1.1/html/vkspec.html#fundamentals-queueoperation-command-types) consume the current state of the command buffer when they are recorded, and will execute state changes on the device as required to match the recorded state.

* **perform synchronization 类型**：set/wait events, pipeline barrier, render pass/subpass dependencies



## 解决 GPU 中的指令依赖

### 问题再何处？

https://www.khronos.org/registry/vulkan/specs/1.1/html/vkspec.html#synchronization-implicit

由于 GPU 是个无情的并行计算怪兽，因此达到 GPU 的指令们很有可能就被打散执行来获得最高效能。同时之前也提到了，虽然 Vulkan 有一个看似能够打包指令的 Command Buffer，但是里面的指令到达 GPU 时也已经被完全打散。这就导致在不显式加以同步的基础上：

- **在一个 Command Buffer 内，Render Pass 之内的同一个 subpass 内指令的执行是满足录制（提交）顺序的。Render Pass 之外的指令执行也满足顺序。**

  action 类型指令，也就是具体干活的指令顺序的保证是由规范中 [Primitive Order](https://www.khronos.org/registry/vulkan/specs/1.1/html/vkspec.html#drawing-primitive-order) 一章提出的。Sync 类型指令也满足隐含的顺序（它们本身就是保证其它指令按顺序执行的，它们都不按顺序执行可就不好办了）。

  当然，如果你的整个渲染流程并没有用到任何 subpass 概念（即一个 Render Pass 内永远只有一个 Subpass，并没有使用 `vkCmdNextSubpass` 来切换 subpass），那么可以认为**整个 Command Buffer 中指令的执行是完全满足录制顺序的。**

  由于图形绘制工作大量使用流水线，所以这些绘制指令也并没有什么必要乱序就能高效的利用 GPU。

- **一条指令内部的图形流水线阶段执行肯定满足顺序。**

  图形流水线一定会按照定义好的流程阶段执行，这也是渲染的根基。试想一下如果 Fragment Shader 跑到 Vertex Shader 之前执行是一种什么样的体验。

- **属于不同 subpass 的指令执行是没有顺序保证的，即如果你有 N 个 subpass，属于这 N 个 subpass 的指令是可能交叉执行的。**

- **向同一个队列提交的不同 Command Buffer，执行时属于不同 Command Buffer 指令很可能会交叉；**

  前面提到了，不能够将 Command Buffer 当作打包指令的容器，因为 GPU 这边看不到这个容器，其只能看见流淌过来的指令。据说 DX12 会保证向同一个 queue 提交的不同 Command Buffer 之间不会重叠执行，但是 Vulkan 可没有这个保证，所以当然会交叉执行喽。

- **向不同队列提交的指令更没有顺序的保证。**

  向不同队列提交指令本意就是让它们能够并行执行，例如一边用 Graphics Queue 显示 Loading 界面一边用一条独立的 Transfer Queue 做高速 DMA Transfer。

对于这些并没有顺序保证的指令，如果它们之间存在依赖（例如一个 pass 需要另一个 pass 的渲染结果送进 Fragment Shader 中采样），则需要下面介绍的各种手段来使得同步这些指令。



### Execution (Pipeline) Barrier



### Memory Barrier

// TODO: memory model



### Image Memory Barrier



### Events



### Subpass Dependencies





## 渲染同步

```
CPU <--Fences--> GPU Graphics Queue <--Semaphore--> GPU Present Queue <--SwapChain--> Monitor Vblank
```





### GPU-GPU 跨队列同步：Semaphore



### CPU-GPU 同步：Fence

> Fences can be used by the host to determine completion of execution of *queue operations*.

Fence 由 GPU 示信，用来告诉 CPU 由 `vkQueueSubmit` 和 `vkQueueBindSparse` 提交的队列任务是否执行完毕。若执行完毕，阻塞方法 `vkWaitForFences` 停止阻塞并返回，继续执行之后的任务。该阻塞方法可以等待多个 Fences，并且可以设定是否等待这些 Fences 都示信，还是其中有一个示信就可以返回。CPU 同时可以通过调用非阻塞方法 `vkGetFenceStatus` 来查询一个 Fence 的状态。

Fence 只有两种状态：signal 和 unsignal。当 GPU 队列任务完成时，跟随提交队列方法提交上来的 Fence 会从 unsignal 变成 signal。想要再次利用这个 Fence 时，需要通过调用 `vkResetFences` 将状态切换到 unsignal。

由于 GPU 示信 Fence 需要将其对应的 Queue 中的任务全部排干，会浪费很多 GPU 时间，所以 Fence 一般被用来控制一帧的渲染。



### 一套渲染同步的策略

有了以上两个概念，我们可以提出如下同步策略：

1. 渲染器必须渲染完这张图之后，呈现引擎才能去拿到（拥有）这张图。

   这里使用 Semaphore，教程中称其为 `renderFinishedSemaphore`；

2. 渲染器必须能从呈现引擎拿到（拥有）一张可供渲染的图，才能对这张图进行渲染。

   这里使用 Semaphore，教程中称其为 `imageAvailableSemaphore`。

3. 当一张图的所有渲染都执行完毕后，才能够开始让客户端发起对于这张图下一次的渲染请求。

   这里使用 Fence，教程中称其为 `inFlightFence`。

下面直接上教程的伪代码，这里只抽象出来了 Fence 和 Semaphore，以及提交和同步相关的方法：

```cpp
VkFence inFlightFence;
VkSemaphore imageAvailableSemaphore;
VkSemaphore renderFinishedSemaphore;

void drawLoop() {
    while (true) {
        vkWaitForFences(inFlightFence); // WILL BLOCK
        uint32_t imageIndex;
        vkAcquireNextImageKHR(after retriving, signal imageAvailableSemaphore) -> imageIndex; // ASYNC (when timeout = 0)
        vkResetFences(inFlightFence);
        // prepare your Command Buffers
        vkQueueSubmit(wait for imageAvailableSemaphore; after execution, signal inFlightFence, renderFinishedSemaphores); // ASYNC
        vkQueuePresentKHR(wait for: renderFinishedSemaphores) // ASYNC
    }
}

void main() {
    prepare();
    drawLoop();
}
```

`vkAcquireNextImageKHR` 这个方法其实非常有趣。在 Swap Chain 一章里提到了，所有被提交到呈现引擎的图，其所有者（ownership）都会变为呈现引擎。我们需要使用这个方法从呈现引擎里要到一张图进行渲染。当我们用非阻塞的参数 (timeout = 0) 调用该方法时，只要呈现引擎中拥有（own）图的时候，该方法便会返回 `VK_SUCCESS`（不考虑不适合的情况）。当然，如果你要了太多图又没 present 但还想要的话，那么就会返回 `VK_NOT_READY`。但是返回了一个成功只代表呈现器有图，你将来可以用这张图，而并不代表这张图现在就能给你用！比如说我在使用 FIFO 配置 Swap Chain 后，一张图必须呈现在屏幕上才能再度交还给渲染器进行渲染，呈现器可能返回给你一个还没呈现的，在FIFO队列里的图的 Index，那我怎么知道什么时候能用呢？这时候就可以使用该方法同样需要传入的 semaphore了，该semaphore将在渲染指令提交时被传入，在GPU渲染之前等待。当这张图的所有者从呈现引擎转移到渲染器时，渲染器即可开始渲染这张图的内容。

上述代码仅存在一个阻塞方法 `vkWaitForFences(inFlightFence)`，而正是这个方法控制了 CPU 上整个 Draw Loop 和 GPU 的时序同步。当 CPU 本身性能足够时，从代码可知，这个阻塞，也就是能否发起下一次渲染请求取决于当前渲染器是否渲染完毕，而渲染器何时渲染完毕取决于呈现引擎何时交给我这张图（呈现引擎比渲染器慢），或者渲染器本身的负载（呈现引擎比渲染器快）。如果渲染器负载大，则 CPU 这边将会阻塞到渲染完毕；如果使用 FIFO 控制 Swap Chain 同时渲染器又足以应付其工作，则呈现引擎交出图的频率则会和表面刷新率一致，该 Draw Loop 的调用频率也就会和表面刷新率一致了，nice！当然，如果还想继续控制时序，例如虽然渲染器和呈现引擎都够快，但是我就想限制帧率（Frame Cap），则需要手动在 CPU 上加以控制（throttle），例如使用 `std::this_thread::sleep_for()`。如今，大多数 PC 游戏和大型手机游戏都能够采用三重缓冲 + CPU throttle 的限制帧率方法，在保证性能不足时的流畅程度（三重缓冲）情况下，同时又保证了整个设备的功耗（手机）和硬件占用（PC）。

















